---
phase: 01-foundation
plan: 03
type: execute
wave: 2
depends_on:
  - 01-01
  - 01-02
files_modified:
  - src/moxie/sync/__init__.py
  - src/moxie/sync/sheets.py
  - scripts/__init__.py
  - scripts/dev_bootstrap.py
  - scripts/seed.py
  - tests/test_sheets_sync.py
autonomous: false
requirements:
  - INFRA-01
  - DATA-03
user_setup:
  - service: google-sheets
    why: "The Google Sheet must be shared with the service account before sheets-sync can authenticate"
    env_vars:
      - name: GOOGLE_SHEETS_ID
        source: "From the Google Sheet URL: docs.google.com/spreadsheets/d/{SHEET_ID}/edit"
      - name: GOOGLE_SHEETS_KEY_PATH
        source: "Path to the service account JSON key file for roxie-sheets@moxie-roxie.iam.gserviceaccount.com"
    dashboard_config:
      - task: "Share the Google Sheet with roxie-sheets@moxie-roxie.iam.gserviceaccount.com (Viewer access minimum)"
        location: "Google Sheets UI → Share button → enter service account email"

must_haves:
  truths:
    - "Running `uv run sheets-sync` (with valid env vars and Sheet shared with service account) prints 'Added: X, Updated: Y, Deleted: Z' and exits 0"
    - "Buildings from the Sheet appear in the buildings table after sheets-sync runs, matchable by querying `SELECT * FROM buildings`"
    - "Running sheets-sync twice does not duplicate buildings — the second run shows Updated: X, Added: 0"
    - "Running `uv run dev` applies migrations and seeds the DB with 3-5 buildings and at least 5 units without error"
    - "The seed DB contains at least one building and one unit queryable via sqlite3"
  artifacts:
    - path: "src/moxie/sync/sheets.py"
      provides: "sheets_sync() function + main() CLI entrypoint"
      contains: "get_all_records"
    - path: "scripts/seed.py"
      provides: "3-5 buildings + 5-10 units inserted into dev DB"
      contains: "SessionLocal"
    - path: "scripts/dev_bootstrap.py"
      provides: "Runs alembic upgrade head then seed.py"
      contains: "alembic upgrade head"
  key_links:
    - from: "src/moxie/sync/sheets.py"
      to: "src/moxie/db/models.py"
      via: "Building model import and session query"
      pattern: "from moxie\\.db\\.models import Building"
    - from: "src/moxie/sync/sheets.py"
      to: "moxie.config"
      via: "GOOGLE_SHEETS_ID and GOOGLE_SHEETS_KEY_PATH env vars"
      pattern: "GOOGLE_SHEETS_KEY_PATH"
    - from: "scripts/dev_bootstrap.py"
      to: "alembic upgrade head"
      via: "subprocess.run"
      pattern: "alembic.*upgrade.*head"
---

<objective>
Build the Google Sheets sync command, seed script, and dev bootstrap — delivering the working `uv run dev` and `uv run sheets-sync` entrypoints required by the phase success criteria.

Purpose: The sheets sync is the live data pipeline that keeps the building list current. The dev bootstrap is the single-command dev environment start that lets Phase 2 scraper development begin immediately with a populated database.
Output: Two CLI commands (`uv run dev`, `uv run sheets-sync`) and a test suite for the sync logic.
</objective>

<execution_context>
@C:/Users/eimil/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/eimil/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/01-foundation/01-CONTEXT.md
@.planning/phases/01-foundation/01-RESEARCH.md
@.planning/phases/01-foundation/01-01-SUMMARY.md
@.planning/phases/01-foundation/01-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Google Sheets sync — sheets_sync() and main() entrypoint</name>
  <files>
    src/moxie/sync/sheets.py
    tests/test_sheets_sync.py
  </files>
  <action>
Create `src/moxie/sync/sheets.py` implementing the sheets sync per the locked decisions:

**`sheets_sync(db: Session) -> dict`** function:
1. Authenticate using `gspread.service_account(filename=GOOGLE_SHEETS_KEY_PATH)` where `GOOGLE_SHEETS_KEY_PATH` comes from `moxie.config`
2. Open sheet by ID: `gc.open_by_key(GOOGLE_SHEETS_ID)`
3. Get the `Buildings` tab: `sh.worksheet("Buildings")` — tab name is case-sensitive
4. Read all rows: `rows = worksheet.get_all_records()` — returns list[dict] keyed by header row
5. Add a row count guard immediately after: if `len(rows) < 1`, raise `ValueError(f"Sheets sync returned suspiciously few rows: {len(rows)}. Check tab name 'Buildings' and that the sheet is shared with the service account.")` — this protects against the silent empty-return pitfall when the tab name is wrong
6. Build `sheet_urls = {row["url"] for row in rows}` for deletion detection
7. Loop through rows: if `existing = db.query(Building).filter_by(url=row["url"]).first()` → update all fields; else → `db.add(Building(...))` with `last_scrape_status="never"`
8. Loop through all DB buildings: if `building.url not in sheet_urls` → `db.delete(building)` (cascade deletes units)
9. `db.commit()`
10. Return `{"added": added, "updated": updated, "deleted": deleted}`

Map these Sheet column names to Building fields (use `.get()` with None default for optional fields):
- `name` → `name`
- `url` → `url`
- `neighborhood` → `neighborhood`
- `management_company` → `management_company`
- `platform` → `platform`
- `rentcafe_property_id` → `rentcafe_property_id` (use `or None` to convert empty string to None)
- `rentcafe_api_token` → `rentcafe_api_token` (use `or None`)

**`main()` function** (the CLI entrypoint registered in pyproject.toml as `sheets-sync`):
```python
def main():
    db_gen = get_db()
    db = next(db_gen)
    try:
        result = sheets_sync(db)
        print(f"Added: {result['added']}, Updated: {result['updated']}, Deleted: {result['deleted']}")
    except Exception as e:
        print(f"Sync failed: {e}")
        raise SystemExit(1)
    finally:
        try:
            next(db_gen)
        except StopIteration:
            pass
```

Create `tests/test_sheets_sync.py` with unit tests that mock `gspread.service_account` and the DB session. Test the following cases:
1. New buildings are added — `added` count increments
2. Existing buildings (same URL) are updated — `updated` count increments, no duplicate rows
3. Buildings missing from Sheet are deleted from DB — `deleted` count increments
4. `len(rows) < 1` raises ValueError
5. Empty string rentcafe fields are stored as None (not empty string)

Use `unittest.mock.patch` for the gspread calls and an in-memory SQLite session for DB assertions.
  </action>
  <verify>
Run: `uv run pytest tests/test_sheets_sync.py -v` — all tests pass.
With valid `.env` and Sheet shared: `uv run sheets-sync` — prints `Added: X, Updated: Y, Deleted: Z` where X > 0 on first run.
  </verify>
  <done>All test_sheets_sync.py tests pass. sheets-sync entrypoint is registered and callable. Sync prints the correct summary line.</done>
</task>

<task type="auto">
  <name>Task 2: Seed script and dev bootstrap command</name>
  <files>
    scripts/__init__.py
    scripts/dev_bootstrap.py
    scripts/seed.py
  </files>
  <action>
Create `scripts/__init__.py` (empty — makes scripts a package importable by uv run dev entrypoint).

Create `scripts/seed.py` — inserts 3-5 representative downtown Chicago apartment buildings with 5-10 units total into the dev database. Seed data must be:
- Realistic enough for Phase 2 filter/query development (varied bed types, rent ranges, neighborhoods)
- Covers all canonical bed types: Studio, Convertible, 1BR, 1BR+Den, 2BR, 3BR+
- Uses the normalizer's `normalize()` to create unit dicts (DO NOT bypass the normalizer for seed data — this proves the pipeline works end-to-end)
- Mix of platforms: at least one 'api', one 'platform', one 'llm' building

Example seed buildings:
- The Reed at Southbank (South Loop, management_company="Related Midwest", platform='api')
- 727 West Madison (West Loop, management_company="Golub", platform='platform')
- Moment River North (River North, management_company="Greystar", platform='llm')

For each building, create 2-4 units with varied raw input to prove normalizer works:
- Mix raw formats: `"$1,500.00"`, `1850`, `"2,200/mo"`
- Mix bed types: `"studio"`, `"1"`, `"1br"`, `"2br"`, `"1 bed den"`
- Mix dates: `"Available Now"`, `"2026-03-01"`, `"March 15, 2026"`

Seed script structure:
```python
from moxie.db.session import SessionLocal
from moxie.db.models import Building, Unit
from moxie.normalizer import normalize
from datetime import datetime

def main():
    db = SessionLocal()
    # ... insert buildings and units
    db.commit()
    db.close()
    print(f"Seeded: {building_count} buildings, {unit_count} units")

if __name__ == "__main__":
    main()
```

Create `scripts/dev_bootstrap.py` — the entrypoint registered as `dev` in pyproject.toml:
```python
import subprocess
import sys
from pathlib import Path

def main():
    """Bootstrap dev environment: run migrations then seed. Invoked via: uv run dev"""
    print("Running migrations...")
    result = subprocess.run(["uv", "run", "alembic", "upgrade", "head"], check=True)

    print("Seeding database...")
    subprocess.run([sys.executable, str(Path(__file__).parent / "seed.py")], check=True)

    print("Dev environment ready.")
    print("Inspect DB: sqlite3 moxie.db")
    print("Run sync: uv run sheets-sync")
    print("Run tests: uv run pytest tests/ -v")

if __name__ == "__main__":
    main()
```

The `dev` command must be idempotent: running it twice on a DB that already has data should not error. Alembic `upgrade head` is already idempotent. The seed script should check if buildings already exist and skip if so (or use upsert by URL) to avoid duplicate key errors on re-run.
  </action>
  <verify>
Run: `uv run python scripts/seed.py` — exits 0, prints seeded count.
Run: `uv run python -c "from moxie.db.session import SessionLocal; from moxie.db.models import Building, Unit; db=SessionLocal(); b=db.query(Building).count(); u=db.query(Unit).count(); print(f'Buildings: {b}, Units: {u}'); assert b >= 3 and u >= 5, f'Insufficient seed data: {b} buildings, {u} units'"` — asserts pass.
Run: `uv run dev` — exits 0, prints "Dev environment ready."
  </verify>
  <done>uv run dev exits 0. Database has at least 3 buildings and 5 units. All 6 canonical bed types are represented across the seeded units. Seed is idempotent (can be run twice without error).</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Verify: Full Phase 1 stack end-to-end</name>
  <what-built>
    Google Sheets sync (uv run sheets-sync), seed script, and dev bootstrap (uv run dev). The full Phase 1 stack is now in place:
    - DB schema with 3 tables
    - Normalizer with full test coverage
    - Sheets sync with mocked test coverage
    - Seed data (3-5 buildings, 5-10 units)
    - Single-command dev startup
  </what-built>
  <how-to-verify>
    1. Ensure `.env` exists with your real values for DATABASE_URL, GOOGLE_SHEETS_ID, GOOGLE_SHEETS_KEY_PATH
    2. Ensure the Google Sheet has been shared with roxie-sheets@moxie-roxie.iam.gserviceaccount.com
    3. Run: `uv run dev` — should print "Dev environment ready." with no errors
    4. Run: `sqlite3 moxie.db "SELECT name, neighborhood, platform FROM buildings;"` — should show seeded buildings
    5. Run: `sqlite3 moxie.db "SELECT unit_number, bed_type, rent_cents, availability_date FROM units;"` — should show seeded units with canonical bed types and integer cents
    6. Run: `uv run sheets-sync` — should print "Added: X, Updated: Y, Deleted: Z" (X > 0 if Sheet has data)
    7. Run: `uv run sheets-sync` again — should show "Added: 0, Updated: X, Deleted: 0" (idempotent)
    8. Run: `uv run pytest tests/ -v` — all tests green
  </how-to-verify>
  <resume-signal>Type "approved" if all 8 checks pass, or describe any failures</resume-signal>
  <action>Human verifies the full Phase 1 stack by running the 8 checks listed in how-to-verify.</action>
  <verify>All 8 checks pass and user types "approved".</verify>
  <done>User confirms: uv run dev exits 0, sqlite3 shows seed data, uv run sheets-sync prints sync summary, uv run pytest all green.</done>
</task>

</tasks>

<verification>
Phase 1 success criteria check (from ROADMAP.md):
1. `uv run sheets-sync` pulls buildings from Google Sheets and upserts — verified by querying buildings table
2. UnitRecord Pydantic schema rejects missing required fields at normalize() time — verified by test_normalizer.py
3. Optional fields (floor_plan, baths, sqft) stored when provided, None when not — verified by test_normalizer.py
4. All scraper output passes through normalize() — verified by seed.py using normalize() directly
5. Dev environment starts with `uv run dev` and includes seed data — verified by sqlite3 query

All 4 requirement IDs covered:
- INFRA-01: sheets sync implemented (plan 03)
- DATA-01: unit table has all required fields (plan 01)
- DATA-02: unit table has all optional nullable fields (plan 01)
- DATA-03: normalizer enforces canonical format (plan 02 + plan 03 seed uses normalize())
</verification>

<success_criteria>
- uv run dev exits 0, DB has ≥3 buildings and ≥5 units
- uv run sheets-sync (with valid env + shared Sheet) exits 0, prints "Added: X, Updated: Y, Deleted: Z"
- uv run sheets-sync run twice shows Added: 0 on second run (idempotent upsert)
- uv run pytest tests/ -v — all tests pass (normalizer + sheets_sync)
- sqlite3 moxie.db shows seed buildings with varied canonical bed types and integer rent_cents
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-03-SUMMARY.md` with:
- What was built (sheets sync, seed, dev bootstrap)
- Seed data inventory (building names, unit counts, bed type coverage)
- Test coverage summary for test_sheets_sync.py
- Any pitfalls encountered (especially gspread auth issues)
- Verification results from the human-verify checkpoint
</output>
