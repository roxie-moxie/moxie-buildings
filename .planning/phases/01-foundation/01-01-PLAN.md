---
phase: 01-foundation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - pyproject.toml
  - .env.example
  - Makefile
  - alembic.ini
  - alembic/env.py
  - alembic/versions/001_initial_schema.py
  - src/moxie/__init__.py
  - src/moxie/config.py
  - src/moxie/db/__init__.py
  - src/moxie/db/models.py
  - src/moxie/db/session.py
autonomous: true
requirements:
  - DATA-01
  - DATA-02

must_haves:
  truths:
    - "Running `alembic upgrade head` creates the buildings, units, and scrape_runs tables without error"
    - "The units table has columns for all required fields: unit_number, bed_type, rent_cents, availability_date, scrape_run_at, building_id"
    - "The units table has columns for all optional fields: floor_plan_name, floor_plan_url, baths, sqft — all nullable"
    - "The units table has a non_canonical boolean column and a unique constraint on (building_id, unit_number)"
    - "The buildings table has all columns from the spec including platform, rentcafe_property_id, rentcafe_api_token, last_scrape_status, last_scraped_at"
    - "Querying `sqlite3 moxie.db '.tables'` shows buildings, units, scrape_runs, and alembic_version tables"
  artifacts:
    - path: "pyproject.toml"
      provides: "uv project config with all dependencies and [project.scripts] entries"
      contains: "sheets-sync"
    - path: "alembic/env.py"
      provides: "Alembic migration config with render_as_batch=True and Base import"
      contains: "render_as_batch"
    - path: "src/moxie/db/models.py"
      provides: "SQLAlchemy 2.0 DeclarativeBase models for Building, Unit, ScrapeRun"
      contains: "class Building"
    - path: "src/moxie/db/session.py"
      provides: "Engine, SessionLocal, get_db factory"
      contains: "check_same_thread"
    - path: ".env.example"
      provides: "Template with all required env var names and placeholder values"
      contains: "GOOGLE_SHEETS_ID"
  key_links:
    - from: "alembic/env.py"
      to: "src/moxie/db/models.py"
      via: "from moxie.db.models import Base"
      pattern: "from moxie\\.db\\.models import Base"
    - from: "src/moxie/db/session.py"
      to: "src/moxie/db/models.py"
      via: "engine bound to Base.metadata"
      pattern: "check_same_thread"
---

<objective>
Establish the project scaffold, SQLAlchemy models, and Alembic migration — the foundational data layer every scraper will write to.

Purpose: The schema is the contract. No Phase 2 scraper can be built until the tables exist and their column types are settled. This plan locks in that contract.
Output: A working uv project with the three-table schema migrated into a SQLite dev database, plus an Alembic env configured for SQLite/PostgreSQL portability.
</objective>

<execution_context>
@C:/Users/eimil/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/eimil/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-foundation/01-CONTEXT.md
@.planning/phases/01-foundation/01-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Project scaffold — pyproject.toml, .env.example, Makefile</name>
  <files>
    pyproject.toml
    .env.example
    Makefile
  </files>
  <action>
Create `pyproject.toml` using the hatchling build backend. Set `requires-python = ">=3.12"`. Register `[project.scripts]` with two entrypoints: `sheets-sync = "moxie.sync.sheets:main"` and `dev = "scripts.dev_bootstrap:main"`. Add all runtime dependencies with pinned versions per the research:

```
sqlalchemy==2.0.46
alembic==1.18.4
pydantic>=2.0
gspread==6.2.1
google-auth>=2.0
python-dotenv>=1.0
python-dateutil>=2.0
```

Add dev dependencies under `[tool.uv.dev-dependencies]`: `pytest>=8.0` and `ruff>=0.9`.

Set up `[tool.ruff]` with `line-length = 100` and `target-version = "py312"`.

Create `.env.example` with exactly these three keys and placeholder values:
```
DATABASE_URL=sqlite:///./moxie.db
GOOGLE_SHEETS_ID=your-google-sheet-id-here
GOOGLE_SHEETS_KEY_PATH=/path/to/service-account-key.json
```

Create a `Makefile` with three targets:
- `dev`: runs `uv run dev`
- `sync`: runs `uv run sheets-sync`
- `test`: runs `uv run pytest tests/ -v`

Run `uv sync` after creating pyproject.toml to install dependencies and generate `uv.lock`.

Do NOT create a `.env` file — it is gitignored and will be created manually by the user. Verify `.gitignore` includes `.env` and `moxie.db`; create `.gitignore` if it does not exist.
  </action>
  <verify>
Run: `uv sync` — exits 0 with no errors.
Run: `uv run python -c "import sqlalchemy, alembic, pydantic, gspread, dotenv, dateutil; print('OK')"` — prints OK.
  </verify>
  <done>All imports succeed. uv.lock file exists. .env.example has all three required keys.</done>
</task>

<task type="auto">
  <name>Task 2: SQLAlchemy 2.0 models — Building, Unit, ScrapeRun</name>
  <files>
    src/moxie/__init__.py
    src/moxie/config.py
    src/moxie/db/__init__.py
    src/moxie/db/models.py
    src/moxie/db/session.py
  </files>
  <action>
Create the package structure: `src/moxie/__init__.py` (empty), `src/moxie/db/__init__.py` (empty).

Create `src/moxie/config.py` with a simple settings loader:
```python
import os
from dotenv import load_dotenv
load_dotenv()

DATABASE_URL: str = os.environ.get("DATABASE_URL", "sqlite:///./moxie.db")
GOOGLE_SHEETS_ID: str = os.environ.get("GOOGLE_SHEETS_ID", "")
GOOGLE_SHEETS_KEY_PATH: str = os.environ.get("GOOGLE_SHEETS_KEY_PATH", "")
```

Create `src/moxie/db/models.py` using SQLAlchemy 2.0 `DeclarativeBase` + `Mapped` syntax (NOT the legacy 1.x `Column()` style). Define three models exactly matching the locked schema:

**Building model** — `__tablename__ = "buildings"`:
- `id: Mapped[int]` — primary key
- `name: Mapped[str]` — nullable=False
- `url: Mapped[str]` — unique=True, nullable=False (upsert key)
- `neighborhood: Mapped[Optional[str]]`
- `management_company: Mapped[Optional[str]]`
- `platform: Mapped[Optional[str]]` — plain String, no enum constraint (per discretion decision)
- `rentcafe_property_id: Mapped[Optional[str]]`
- `rentcafe_api_token: Mapped[Optional[str]]`
- `last_scrape_status: Mapped[str]` — server_default="never", nullable=False
- `last_scraped_at: Mapped[Optional[datetime]]`
- Relationships: `units` and `scrape_runs` with `cascade="all, delete-orphan"`

**Unit model** — `__tablename__ = "units"`:
- `__table_args__` with: `UniqueConstraint("building_id", "unit_number", name="uq_unit_building_number")`, and four indexes: `ix_units_bed_type`, `ix_units_rent_cents`, `ix_units_availability_date`, `ix_units_building_id`
- `id: Mapped[int]` — primary key
- `building_id: Mapped[int]` — ForeignKey("buildings.id"), nullable=False
- `unit_number: Mapped[str]` — nullable=False
- `bed_type: Mapped[str]` — nullable=False
- `non_canonical: Mapped[bool]` — default=False (CRITICAL: must be present before first migration)
- `rent_cents: Mapped[int]` — nullable=False
- `availability_date: Mapped[str]` — nullable=False, stored as YYYY-MM-DD ISO string
- `floor_plan_name: Mapped[Optional[str]]`
- `floor_plan_url: Mapped[Optional[str]]`
- `baths: Mapped[Optional[str]]`
- `sqft: Mapped[Optional[int]]`
- `scrape_run_at: Mapped[datetime]` — nullable=False
- Relationship: `building` back_populates="units"

**ScrapeRun model** — `__tablename__ = "scrape_runs"`:
- `id: Mapped[int]` — primary key
- `building_id: Mapped[int]` — ForeignKey("buildings.id"), nullable=False
- `run_at: Mapped[datetime]` — nullable=False
- `status: Mapped[str]` — nullable=False ('success' | 'failed')
- `unit_count: Mapped[int]` — nullable=False, default=0
- `error_message: Mapped[Optional[str]]`
- Relationship: `building` back_populates="scrape_runs"

Create `src/moxie/db/session.py`:
```python
from moxie.config import DATABASE_URL
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, Session
from typing import Generator

connect_args = {}
if DATABASE_URL.startswith("sqlite"):
    connect_args["check_same_thread"] = False  # required for SQLite multi-threaded use

engine = create_engine(DATABASE_URL, connect_args=connect_args)
SessionLocal = sessionmaker(bind=engine, autocommit=False, autoflush=False)

def get_db() -> Generator[Session, None, None]:
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()
```
  </action>
  <verify>
Run: `uv run python -c "from moxie.db.models import Building, Unit, ScrapeRun, Base; print('Models OK')"` — prints "Models OK" with no errors.
Run: `uv run python -c "from moxie.db.session import engine, SessionLocal, get_db; print('Session OK')"` — prints "Session OK".
  </verify>
  <done>All three models import cleanly. Session factory and get_db are importable. non_canonical column is defined on Unit model.</done>
</task>

<task type="auto">
  <name>Task 3: Alembic setup and initial migration</name>
  <files>
    alembic.ini
    alembic/env.py
    alembic/versions/
  </files>
  <action>
Run `uv run alembic init alembic` to generate `alembic.ini` and `alembic/env.py`. Then customize `alembic/env.py` with these critical changes:

1. Add at the top, before any other imports:
```python
import os
from dotenv import load_dotenv
load_dotenv()
```

2. Add the model import (CRITICAL — without this, autogenerate produces an empty migration):
```python
from moxie.db.models import Base  # noqa: F401 — registers all models on Base.metadata
```

3. Set the database URL from the environment:
```python
config.set_main_option("sqlalchemy.url", os.environ.get("DATABASE_URL", "sqlite:///./moxie.db"))
```

4. Set `target_metadata = Base.metadata`

5. In the `run_migrations_online()` function, add `render_as_batch=True` to the `context.configure()` call (CRITICAL — without this, column alterations will fail on SQLite):
```python
context.configure(
    connection=connection,
    target_metadata=target_metadata,
    render_as_batch=True,
)
```

Also set `render_as_batch=True` in the offline function if it exists.

After customizing env.py, run:
```bash
uv run alembic revision --autogenerate -m "initial schema"
```

Verify the generated migration file in `alembic/versions/` contains `create_table` calls for `buildings`, `units`, and `scrape_runs`. If the migration is empty (upgrade/downgrade have no ops), the model import in env.py is missing — fix and re-run.

Then apply the migration:
```bash
uv run alembic upgrade head
```

Verify the schema with:
```bash
uv run python -c "
import sqlite3
conn = sqlite3.connect('moxie.db')
print(conn.execute(\"SELECT name FROM sqlite_master WHERE type='table'\").fetchall())
conn.close()
"
```

Expected output includes: buildings, units, scrape_runs, alembic_version.
  </action>
  <verify>
Run: `uv run alembic current` — shows current revision (not "(head)" on a blank DB yet, but no error).
Run: `uv run alembic upgrade head` — exits 0.
Run: `uv run python -c "import sqlite3; conn=sqlite3.connect('moxie.db'); tables=[r[0] for r in conn.execute(\"SELECT name FROM sqlite_master WHERE type='table'\").fetchall()]; print(tables); assert 'buildings' in tables and 'units' in tables and 'scrape_runs' in tables, 'Missing tables'"` — asserts pass, tables listed.
Run: `uv run python -c "import sqlite3; conn=sqlite3.connect('moxie.db'); cols=[r[1] for r in conn.execute('PRAGMA table_info(units)').fetchall()]; print(cols); assert 'non_canonical' in cols, 'non_canonical missing'"` — asserts pass.
  </verify>
  <done>alembic upgrade head exits 0. buildings, units, scrape_runs, and alembic_version tables all exist in moxie.db. units table has non_canonical column. Migration file in alembic/versions/ is non-empty.</done>
</task>

</tasks>

<verification>
After all tasks complete:
1. `uv run python -c "from moxie.db.models import Building, Unit, ScrapeRun, Base; from moxie.db.session import engine, get_db; print('All imports OK')"` — no errors
2. `uv run alembic upgrade head` — exits 0 (idempotent, already at head)
3. Schema check: buildings, units, scrape_runs tables exist with correct columns
4. non_canonical column present on units table
5. .env.example committed with DATABASE_URL, GOOGLE_SHEETS_ID, GOOGLE_SHEETS_KEY_PATH
</verification>

<success_criteria>
- pyproject.toml has all deps and [project.scripts] with sheets-sync and dev entries
- uv sync exits 0, all imports succeed
- alembic upgrade head exits 0 on a clean database
- buildings table: id, name, url (unique), neighborhood, management_company, platform, rentcafe_property_id, rentcafe_api_token, last_scrape_status, last_scraped_at
- units table: id, building_id (FK), unit_number, bed_type, non_canonical, rent_cents, availability_date, floor_plan_name, floor_plan_url, baths, sqft, scrape_run_at + unique constraint on (building_id, unit_number)
- scrape_runs table: id, building_id (FK), run_at, status, unit_count, error_message
- alembic/env.py has render_as_batch=True and imports Base from moxie.db.models
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-01-SUMMARY.md` with:
- What was built (scaffold, models, migration)
- Key decisions made (model organization, index choices, platform as plain string)
- File inventory with brief description of each file's role
- Any deviations from plan and why
- Verification results
</output>
