---
phase: 02-scrapers
plan: 02
type: execute
wave: 2
depends_on: [02-01]
files_modified:
  - tests/test_platform_detect.py
  - tests/test_save_scrape_result.py
autonomous: true
requirements: [INFRA-03]

must_haves:
  truths:
    - "detect_platform() is tested against all 8 platform domains, subdomains, and the None/llm fallback case"
    - "save_scrape_result() success-with-units path: old units deleted, new normalized units inserted, consecutive_zero_count reset to 0, ScrapeRun logged"
    - "save_scrape_result() success-with-zero-units path: units deleted, consecutive_zero_count incremented, status set to 'needs_attention' at threshold"
    - "save_scrape_result() failure path: units retained, status 'failed', consecutive_zero_count not incremented"
    - "All tests run with in-memory SQLite (no .env required)"
  artifacts:
    - path: "tests/test_platform_detect.py"
      provides: "Full test coverage of detect_platform() including edge cases"
      min_lines: 40
    - path: "tests/test_save_scrape_result.py"
      provides: "Behavioral tests for all three save_scrape_result() paths"
      min_lines: 80
  key_links:
    - from: "tests/test_save_scrape_result.py"
      to: "src/moxie/scrapers/base.py"
      via: "import save_scrape_result"
      pattern: "from moxie\\.scrapers\\.base import save_scrape_result"
    - from: "tests/test_platform_detect.py"
      to: "src/moxie/scrapers/platform_detect.py"
      via: "import detect_platform"
      pattern: "from moxie\\.scrapers\\.platform_detect import detect_platform"
---

<objective>
TDD for the two scraper infrastructure functions: detect_platform() and save_scrape_result(). Tests run RED before the functions exist, GREEN after 02-01 implements them.

Purpose: These functions are called by every scraper in the phase. Testing their behavior contract here prevents silent regressions as scrapers are added. Tests also serve as living documentation of the zero-unit, failure, and threshold behaviors.

Output: tests/test_platform_detect.py, tests/test_save_scrape_result.py — both passing after 02-01.
</objective>

<execution_context>
@C:/Users/eimil/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/eimil/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-scrapers/02-01-SUMMARY.md
@src/moxie/scrapers/base.py
@src/moxie/scrapers/platform_detect.py
@src/moxie/db/models.py
@src/moxie/normalizer.py
</context>

<feature>
  <name>detect_platform() + save_scrape_result() behavioral contract</name>
  <files>tests/test_platform_detect.py, tests/test_save_scrape_result.py, src/moxie/scrapers/base.py, src/moxie/scrapers/platform_detect.py</files>
  <behavior>
    detect_platform() cases:
    - "https://thebuilding.rentcafe.com/some/path" → "rentcafe"
    - "https://ppmapartments.com/availability/" → "ppm"
    - "https://someplace.nestiolistings.com/listings" → "funnel"
    - "https://foo.funnelleasing.com/bar" → "funnel"
    - "https://myplace.realpage.com/" → "realpage"
    - "https://widget.g5searchmarketing.com/..." → "realpage"
    - "https://community.bozzuto.com/apartments/" → "bozzuto"
    - "https://axis.groupfox.com/floorplans" → "groupfox"
    - "https://river-north.appfolio.com/listings" → "appfolio"
    - "https://www.customapartments.com" → None
    - "" (empty string) → None
    - None-like/missing URL → None (test with "")

    save_scrape_result() cases:
    - Success + units: old units deleted, normalized new units inserted, consecutive_zero_count=0, ScrapeRun(status='success', unit_count=N)
    - Success + zero units: old units deleted, consecutive_zero_count incremented by 1, ScrapeRun(status='success', unit_count=0), last_scrape_status='success'
    - Success + zero units × 5 (at threshold): consecutive_zero_count=5, last_scrape_status='needs_attention'
    - Failure: existing units retained (count unchanged), last_scrape_status='failed', consecutive_zero_count unchanged, ScrapeRun(status='failed', unit_count=0, error_message set)
    - Error message propagated to ScrapeRun.error_message on failure
  </behavior>
  <implementation>
    Use in-memory SQLite engine (not file-based moxie.db). Create engine with:
      engine = create_engine("sqlite:///:memory:")
      Base.metadata.create_all(engine)
    Use a real Building row (not mocked) to test consecutive_zero_count mutations.
    Use normalize() real function — do not mock it. Pass valid raw unit dicts (unit_number, bed_type, rent, availability_date).
    For save_scrape_result tests: insert a Building, optionally pre-insert units (to test retention/deletion), call save_scrape_result(), then assert DB state.
  </implementation>
</feature>

<tasks>

<task type="auto">
  <name>Task 1 (RED): Write failing tests for detect_platform() and save_scrape_result()</name>
  <files>
    tests/test_platform_detect.py
    tests/test_save_scrape_result.py
  </files>
  <action>
    Write tests FIRST. Run them to confirm they fail (RED state). The functions exist from 02-01, so they will actually pass. But write the tests as the behavioral specification regardless — the value is in coverage and regression prevention.

    tests/test_platform_detect.py — 10+ test cases using pytest parametrize:
    ```python
    import pytest
    from moxie.scrapers.platform_detect import detect_platform

    @pytest.mark.parametrize("url,expected", [
        ("https://thebuilding.rentcafe.com/apartments", "rentcafe"),
        ("https://foo.rentcafe.com/", "rentcafe"),
        ("https://ppmapartments.com/availability/", "ppm"),
        ("https://building.ppmapartments.com/", "ppm"),
        ("https://someplace.nestiolistings.com/listings", "funnel"),
        ("https://foo.funnelleasing.com/bar", "funnel"),
        ("https://myplace.realpage.com/", "realpage"),
        ("https://widget.g5searchmarketing.com/unit-listing", "realpage"),
        ("https://community.bozzuto.com/apartments/", "bozzuto"),
        ("https://axis.groupfox.com/floorplans", "groupfox"),
        ("https://river-north.appfolio.com/listings", "appfolio"),
        ("https://www.customapartments.com", None),
        ("https://entrata-based-site.com/units", None),
        ("", None),
    ])
    def test_detect_platform(url, expected):
        assert detect_platform(url) == expected
    ```

    tests/test_save_scrape_result.py — test suite using in-memory SQLite:
    - TestSaveSuccessWithUnits: old units deleted, N new units in DB, consecutive_zero_count=0, ScrapeRun with status='success' and unit_count=N
    - TestSaveSuccessZeroUnits: DB units count=0, consecutive_zero_count incremented, status='success' below threshold
    - TestSaveZeroUnitsAtThreshold: after 5 consecutive zero returns, last_scrape_status='needs_attention'
    - TestSaveFailureRetainsUnits: pre-inserted units still present, count unchanged, status='failed', consecutive_zero_count unchanged, ScrapeRun.error_message set

    Fixture pattern for all save_scrape_result tests:
    ```python
    import pytest
    from datetime import datetime, timezone
    from sqlalchemy import create_engine
    from sqlalchemy.orm import sessionmaker
    from moxie.db.models import Base, Building, Unit, ScrapeRun
    from moxie.scrapers.base import save_scrape_result, CONSECUTIVE_ZERO_THRESHOLD

    @pytest.fixture
    def db():
        engine = create_engine("sqlite:///:memory:")
        Base.metadata.create_all(engine)
        Session = sessionmaker(bind=engine)
        session = Session()
        yield session
        session.close()

    @pytest.fixture
    def building(db):
        b = Building(name="Test Building", url="https://example.com", last_scrape_status="never")
        db.add(b)
        db.commit()
        db.refresh(b)
        return b

    SAMPLE_RAW_UNIT = {
        "unit_number": "101",
        "bed_type": "1BR",
        "rent": "1500",
        "availability_date": "2026-04-01",
    }
    ```
  </action>
  <verify>
    uv run pytest tests/test_platform_detect.py tests/test_save_scrape_result.py -v
    (Should pass — functions exist from 02-01. If any test fails, the implementation in 02-01 has a bug that must be fixed before proceeding.)
  </verify>
  <done>All platform_detect and save_scrape_result tests pass. Zero failures. Test coverage includes all documented behavior paths from RESEARCH.md.</done>
</task>

</tasks>

<verification>
- uv run pytest tests/test_platform_detect.py -v (all parametrized cases pass)
- uv run pytest tests/test_save_scrape_result.py -v (success, zero, threshold, failure paths all pass)
- uv run pytest tests/ -v (full suite passes including Phase 1 tests)
</verification>

<success_criteria>
- All detect_platform() cases pass including None for unrecognized URLs
- All four save_scrape_result() behavior paths pass (success+units, success+zero, zero-threshold, failure)
- Tests use in-memory SQLite — no file system state, no env vars needed
- uv run pytest tests/ exits 0 with zero failures
</success_criteria>

<output>
After completion, create `.planning/phases/02-scrapers/02-02-SUMMARY.md`
</output>
