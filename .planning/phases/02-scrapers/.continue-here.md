---
phase: 02-scrapers
task: gap-closure
status: in_progress
last_updated: 2026-02-19T15:44:30.575Z
---

<current_state>
Platform classification and credential extraction session is complete. 236 buildings
classified as 'rentcafe'. RentCafe credential extraction script rewrote twice — final
state uses Playwright request interception but is UNCOMMITTED. Root cause discovered:
apiToken is server-to-server only (never exposed client-side). Script needs to be
committed as-is (it's the correct architecture doc + VoyagerPropertyCode extraction
logic), then the credential strategy needs a decision.
</current_state>

<completed_work>

### This session (2026-02-19)

- Built `scripts/detect_platforms.py` — HTML-signature-based platform detector
  - Targets `needs_classification` buildings by default; `--all` flag for all
  - PLATFORM_SIGNATURES for rentcafe, entrata, appfolio, realpage, funnel, bozzuto, groupfox, mri, knock, yardi
  - Registered as `detect-platforms` in pyproject.toml
  - Run on 131 unknowns → 55 detected, 69 unknown, 7 errors

- Added MRI Software platform everywhere:
  - `detect_platforms.py` PLATFORM_SIGNATURES + PLATFORM_CHECK_ORDER
  - `platform_detect.py` URL patterns + KNOWN_PLATFORMS
  - `scrape.py` dispatch table (→ llm fallback, no scraper yet)

- Fixed 9 pre-existing test failures (all 253 now passing):
  - LLM scraper: FakeResult mock missing `.links` and `.html` attributes
  - Sheets sync: `platform` key in expected output; `needs_classification` assertion

- DB cleanup:
  - Deleted empty-name / email-URL row (regal@chicagorentals.com)
  - Fixed `platform='platform'` header leak on "727 W Madison" → `needs_classification`

- Manual cluster classifications (applied to DB):
  - Arrive LEX, Michigan Ave, South Loop, Streeterville → `mri`
  - Wolf Point East, Wolf Point West → `mri`
  - Reside at 2525 → `rentcafe`

- Rewrote `extract_rentcafe_credentials.py` to use Playwright request interception
  (replaced Crawl4AI HTML scraping; two-pass link-following also tried)
  UNCOMMITTED — docstring documents architecture discovery

### Previous sessions (from STATE.md)
- `scrape` CLI command — spot-check any building
- LLM scraper two-pass crawl + strengthened prompt/filter
- `sheets_sync` Platform column support + `needs_classification` sentinel
- `export-platforms` command
- RentCafe scraper real API implementation (replaced stub)
- `sheets-sync` run on real ~400 buildings
- All 9 scraper plan tests passing

</completed_work>

<remaining_work>

### Immediate: commit WIP
- Commit `scripts/extract_rentcafe_credentials.py` (Playwright version + docstring)
  This is the correct implementation but fundamentally can't extract apiToken — documented.

### RentCafe credential strategy decision (BLOCKER for rentcafe scraping)
Two paths:
A. Extract VoyagerPropertyCode automatically (from securecafe subdomain in homepage HTML)
   + collect apiToken manually via DevTools once per management company
   (~5-10 management companies, one token each unlocks all their buildings)
B. Skip RentCafe-specific scraper; use LLM scraper for all 236 rentcafe buildings
   (expensive: ~$8-9/day just for rentcafe at $0.03-0.05/building)

Recommended: Path A — extract VoyagerPropertyCode at scale now, collect apiToken
manually for the top management companies first (they represent most buildings).

### Platform classification tail (not blocking)
- 75 buildings still `needs_classification`
- User said: "75 unknowns aren't blocking anything — don't let the unknown tail wag the dog"
- These can be assigned `llm` platform in bulk if needed; or left for Alex to review

### Validation gaps (from Phase 2 verification report, score 3/5)
- SC1/SC3: RentCafe scraper ready but needs credentials populated in DB
- SC5: Post-scrape bed type audit (`SELECT COUNT(*) FROM units WHERE non_canonical = 1`)
- Tier 2 CSS selectors (Funnel, AppFolio, Bozzuto, RealPage, Groupfox) — not validated live
- LLM scraper needs re-validation after link-following fix

</remaining_work>

<decisions_made>

- [2026-02-19] Platform-by-DB not URL: `extract_rentcafe_credentials.py` now queries
  `Building.platform == "rentcafe"` (not ILIKE). All 237 rentcafe buildings have
  custom domains — URL pattern matching doesn't apply.

- [2026-02-19] MRI Software = Arrive + Wolf Point clusters: Manual inspection of rendered
  HTML confirmed `mri` + `residentportal.com` signatures. Added to all detection systems.
  4 Arrive buildings + 2 Wolf Point → `mri` platform (uses LLM fallback, no MRI scraper).

- [2026-02-19] apiToken architecture confirmed (unresolvable without manual action):
  - VoyagerPropertyCode = securecafe.com subdomain (e.g., "fisherbuildingchicago")
    → Can be extracted automatically from homepage HTML
  - apiToken = server-side only. RentCafe calls api.rentcafe.com internally;
    the token never appears in any client-side resource.
  - Floor plans pages Cloudflare-challenge headless browsers (CDN-CGI challenge XHRs)
  - Three extraction approaches tried and all returned 0/236: HTML scraping, two-pass
    link-following, Playwright request interception

- [2026-02-19] 75 needs_classification buildings are not a blocker for Phase 2 close.

</decisions_made>

<blockers>

- **RentCafe apiToken**: Cannot be extracted automatically. Must be captured manually
  via DevTools (Network tab → filter "rentcafeapi" → copy apiToken from request URL).
  One token per management company. Top companies: ~5-10 companies cover ~200+ buildings.
  Status: Unblocked for VoyagerPropertyCode; blocked on apiToken collection.

- **7 bot-blocked buildings** (BJB Properties trio + Millennium Park Plaza +
  Lincoln Park Mews + Motif on Belden + one other): Hard Cloudflare blocks, returned
  empty HTML on all retry attempts. Cannot auto-classify.

</blockers>

<context>
Platform classification is largely done (332/407 = 82% classified). The big remaining
work is getting RentCafe credentials so the scraper can actually run. The scraper code
is correct — it just needs VoyagerPropertyCode + apiToken per building.

VoyagerPropertyCode strategy: update extract_rentcafe_credentials.py to ONLY extract
the VoyagerPropertyCode (from securecafe subdomain URL in homepage HTML, not network
requests), since apiToken is unextractable automatically.

For apiToken: approach is "one-time DevTools session per management company." Fisher
Building = Golub & Company. Identify the management companies behind the 237 rentcafe
buildings, group by company, get one token per company. Probably 10-15 sessions covers
80%+ of buildings.

After credentials: the rentcafe scraper (already implemented and tested) will work
immediately. Then validate Tier 2 CSS scrapers against live pages. Then Phase 3 scheduler.
</context>

<next_action>
1. Commit `scripts/extract_rentcafe_credentials.py` as WIP (it's the correct Playwright
   implementation — documents the architecture; the VoyagerPropertyCode extraction
   can be adapted from its link-scanning logic).

2. Decide on VoyagerPropertyCode extraction approach: the script's homepage link-scan
   logic can be adapted to look for securecafe.com links in the page DOM rather than
   intercepting network requests. This should work without Cloudflare issues.

3. For apiToken: list the management companies behind rentcafe buildings in DB,
   prioritize by building count, then do DevTools captures per company.
</next_action>
