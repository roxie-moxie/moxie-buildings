---
phase: 02-scrapers
plan: 06
type: execute
wave: 3
depends_on: [02-01]
files_modified:
  - src/moxie/scrapers/tier2/bozzuto.py
  - tests/test_scraper_bozzuto.py
autonomous: true
requirements: [SCRAP-06]

must_haves:
  truths:
    - "bozzuto.scrape(building) fetches the building's URL with httpx + browser-like headers and parses unit data with BeautifulSoup"
    - "On non-2xx response, raises BozzutoScraperError (signals failure to save_scrape_result)"
    - "_parse_html() extracts units into list[dict] with unit_number, bed_type, rent, availability_date"
    - "If httpx returns a 403 or bot-detection response, the scraper raises BozzutoScraperError with a message recommending Crawl4AI upgrade"
  artifacts:
    - path: "src/moxie/scrapers/tier2/bozzuto.py"
      provides: "Bozzuto HTML scraper using httpx + BeautifulSoup with Crawl4AI upgrade path"
      exports: ["scrape"]
    - path: "tests/test_scraper_bozzuto.py"
      provides: "Tests for Bozzuto parsing and HTTP error handling"
      min_lines: 25
  key_links:
    - from: "src/moxie/scrapers/tier2/bozzuto.py"
      to: "httpx"
      via: "httpx.Client.get() for HTML fetch"
      pattern: "httpx\\.Client"
---

<objective>
Build the Bozzuto HTML scraper for ~13 buildings. Bozzuto is a custom platform with no public API. httpx + BeautifulSoup is the starting approach, with a documented Crawl4AI upgrade path if bot detection is encountered.

Purpose: Bozzuto manages ~13 buildings across the portfolio. Their custom site consistently exposes unit listings via HTML. The scraper provides the same list[dict] interface as all other Tier 2 scrapers.

Output: tier2/bozzuto.py, tests/test_scraper_bozzuto.py.
</objective>

<execution_context>
@C:/Users/eimil/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/eimil/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-scrapers/02-01-SUMMARY.md
@src/moxie/db/models.py
@src/moxie/scrapers/base.py
@src/moxie/normalizer.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Bozzuto HTML scraper with bot-detection upgrade path</name>
  <files>
    src/moxie/scrapers/tier2/bozzuto.py
    tests/test_scraper_bozzuto.py
  </files>
  <action>
    Create src/moxie/scrapers/tier2/bozzuto.py:

    ```python
    """
    Bozzuto scraper — Tier 2 HTML.

    Bozzuto manages a custom property website platform used across ~13 buildings.
    No public API — HTML scraping is required.

    Approach: httpx + BeautifulSoup with realistic browser headers.
    Upgrade path: If sites return 403 or bot-detection pages, switch to Crawl4AI
    (same pattern as groupfox.py). Uncomment the Crawl4AI block in _fetch_html()
    and remove the httpx block.

    SELECTOR NOTE: Bozzuto listing page HTML structure was not directly inspectable
    during research. CSS selectors MUST be verified against a real bozzuto.com
    property URL before trusting output. Common Bozzuto patterns include
    .available-apartments, .unit-listing, [data-available] attributes.

    Platform: 'bozzuto'
    Coverage: ~13 buildings
    """
    import httpx
    from bs4 import BeautifulSoup
    from moxie.db.models import Building

    _HEADERS = {
        "User-Agent": (
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/120.0.0.0 Safari/537.36"
        ),
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
        "Accept-Language": "en-US,en;q=0.9",
    }

    # HTTP status codes that suggest bot detection (should trigger Crawl4AI upgrade)
    _BOT_DETECTION_STATUSES = {403, 429, 503}


    class BozzutoScraperError(RuntimeError):
        """Raised on HTTP error or bot detection. Signals scrape_succeeded=False."""


    def _fetch_html(url: str) -> str:
        """
        Fetch Bozzuto listing page HTML with browser-like headers.

        If a bot-detection status code is received, raises BozzutoScraperError
        with a message recommending Crawl4AI upgrade.

        CRAWL4AI UPGRADE: If httpx consistently returns 403, replace with:
          import asyncio
          from crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode
          async def _async_fetch(url):
              config = CrawlerRunConfig(cache_mode=CacheMode.BYPASS)
              async with AsyncWebCrawler() as crawler:
                  result = await crawler.arun(url, config=config)
              return result.html or ""
          return asyncio.run(_async_fetch(url))
        """
        with httpx.Client(timeout=30.0, headers=_HEADERS, follow_redirects=True) as client:
            response = client.get(url)

        if response.status_code in _BOT_DETECTION_STATUSES:
            raise BozzutoScraperError(
                f"Bozzuto site returned HTTP {response.status_code} (likely bot detection) "
                f"for {url}. Upgrade _fetch_html() to use Crawl4AI (see inline comment)."
            )
        if response.status_code != 200:
            raise BozzutoScraperError(
                f"Bozzuto listing page returned HTTP {response.status_code} for {url}"
            )
        return response.text


    def _parse_html(html: str) -> list[dict]:
        """
        Parse unit data from Bozzuto listing page HTML.

        SELECTOR VERIFICATION REQUIRED: Verify these selectors against a real
        bozzuto.com property URL before production use.

        Common Bozzuto page patterns observed:
        - Unit cards with class 'available-apartment' or 'fp-apartment'
        - Bed type in '.fp-bedrooms', '.bed-count', or '[data-beds]'
        - Rent in '.fp-rent', '.price', or '[data-price]'
        - Unit number in '.fp-unit', '.unit-number'
        - Availability in '.fp-available', '.availability-date'
        """
        soup = BeautifulSoup(html, "html.parser")
        units = []

        selectors = [
            "[class*='available-apartment']",
            "[class*='fp-apartment']",
            "[class*='unit-card']",
            "[class*='apartment-item']",
        ]

        unit_elements = []
        for sel in selectors:
            unit_elements = soup.select(sel)
            if unit_elements:
                break  # use first selector that matches

        for unit_el in unit_elements:
            bed_el = unit_el.select_one("[class*='bedroom'], [class*='bed'], [data-beds]")
            rent_el = unit_el.select_one("[class*='rent'], [class*='price'], [data-price]")
            avail_el = unit_el.select_one("[class*='avail'], [class*='available'], [class*='move-in']")
            num_el = unit_el.select_one("[class*='unit-number'], [class*='unit-name'], [class*='fp-unit']")

            if not (bed_el and rent_el):
                continue

            units.append({
                "unit_number": num_el.get_text(strip=True) if num_el else "N/A",
                "bed_type": bed_el.get_text(strip=True),
                "rent": rent_el.get_text(strip=True),
                "availability_date": avail_el.get_text(strip=True) if avail_el else "Available Now",
            })

        return units


    def scrape(building: Building) -> list[dict]:
        """
        Scrape unit availability from a Bozzuto property page.

        Returns list of raw unit dicts for normalize() / save_scrape_result().
        Raises BozzutoScraperError on HTTP error or bot detection.
        """
        html = _fetch_html(building.url)
        return _parse_html(html)
    ```

    Create tests/test_scraper_bozzuto.py:
    - test_parse_html_empty_returns_empty_list
    - test_parse_html_extracts_units: HTML fixture with Bozzuto-like markup → list of unit dicts
    - test_fetch_html_raises_bot_detection_on_403: pytest-httpx mock 403 → BozzutoScraperError with "bot detection" in message
    - test_fetch_html_raises_on_generic_error: mock 500 → BozzutoScraperError
    - test_fetch_html_returns_html_on_200: mock 200 → returns html string
    - test_scrape_raises_on_http_error: full scrape() call with mocked 404 → BozzutoScraperError

    Sample HTML fixture:
    ```python
    SAMPLE_HTML = """
    <div class="available-apartment">
      <span class="bedroom-count">1 Bedroom</span>
      <span class="fp-rent">$2,100</span>
      <span class="fp-available">March 15, 2026</span>
      <span class="fp-unit">1A</span>
    </div>
    <div class="available-apartment">
      <span class="bedroom-count">Studio</span>
      <span class="fp-rent">$1,650</span>
      <span class="fp-available">Available Now</span>
      <span class="fp-unit">5C</span>
    </div>
    """
    ```
  </action>
  <verify>
    uv run pytest tests/test_scraper_bozzuto.py -v (all tests pass)
    uv run pytest tests/ -v (full suite passes)
    uv run python -c "from moxie.scrapers.tier2.bozzuto import scrape; print('import ok')"
  </verify>
  <done>Bozzuto scraper importable with scrape(building) interface. Bot-detection error handling documented and tested. Crawl4AI upgrade path documented inline. All tests pass without real HTTP calls.</done>
</task>

</tasks>

<verification>
- uv run pytest tests/test_scraper_bozzuto.py -v
- uv run pytest tests/ -v (zero failures)
</verification>

<success_criteria>
- BozzutoScraperError raised on 403/429/503 with message noting Crawl4AI upgrade path
- HTML parsing uses BeautifulSoup with multi-selector fallback strategy
- All tests pass without real network calls
- Crawl4AI upgrade path documented in inline comment for easy activation
</success_criteria>

<output>
After completion, create `.planning/phases/02-scrapers/02-06-SUMMARY.md`
</output>
